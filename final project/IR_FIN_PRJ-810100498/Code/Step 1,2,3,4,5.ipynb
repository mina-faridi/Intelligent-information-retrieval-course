{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a217d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T13:54:48.262388Z",
     "start_time": "2022-01-14T13:54:16.257136Z"
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy\n",
    "import pandas\n",
    "import nltk\n",
    "import csv\n",
    "import numpy\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e653dbe5",
   "metadata": {},
   "source": [
    "# Step 1: Data Pre-Processing\n",
    "<div style=\"direction:rtl  ; font-family: 'Nunito', sans-serif;\" > \n",
    "    \n",
    "برای اجرای کدها بایستی که فایل‌های train_data.xml، dev_data.xml و test_data.xml که همان فایل‌های اولیه ارائه شده در تمرین است و نیز فایل‌های pa_pp_train_data.csv، pa_pp_dev_data.csv و pa_pp_test_data.csv در کنار فایل نوت بوک ژوپیتر قرار داشته باشند.\n",
    "    \n",
    "    \n",
    "ابتدا مراحل پیش پردازش را به این صورت انجام می‌دهیم که نخست متن سوالات و پاسخ‌های ورودی را با کمک کتابخانه nltk توکن‌توکن می‌کنیم. بعد از حذف استاپ ورد‌ها، کوچک‌سازی حروف و استم کردن با PorterStemmer را بازهم با استفاده از کتابخانه nltk انجام می‌دهیم در ادامه بخش‌های مورد نیاز از داده‌ها یعنی:\n",
    "•\tRELQ_ID\n",
    "•\tRelQBody\n",
    "•\tRELC_ID\n",
    "•\tRELC_RELEVANCE2RELQ\n",
    "•\tRelCText\n",
    "را از فایل‌های train_data.xml، dev_data.xml و test_data.xml جدا می‌کنیم. برای صفت RelCText به ازای مقدار Good عدد 2، PotentiallyUseful عدد 1 و به ازای Bad عدد 0 در نظر می‌گیریم و به صورت مناسب به ترتیب در فایل‌های pa_pp_train_data.csv، pa_pp_dev_data.csv و pa_pp_test_data.csv ذخیره می‌کنیم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c662640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T13:54:48.333410Z",
     "start_time": "2022-01-14T13:54:48.327811Z"
    }
   },
   "outputs": [],
   "source": [
    "ANSWER_LABELS_MAPPING = {'False': 0, 'True': 1, 'NonFactual': 2}\n",
    "label_array = ['Bad', 'PotentiallyUseful','Good']\n",
    "test_label_array = ['?']\n",
    "QUESTION_LABELS_MAPPING = {'Opinion': 0, 'Factual': 1, 'Socializing': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28e429a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T13:54:48.714834Z",
     "start_time": "2022-01-14T13:54:48.350971Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_label(original_label, label_mapping):\n",
    "    if original_label in label_mapping.keys():\n",
    "        return label_mapping[original_label]\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2b4afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T13:54:48.859647Z",
     "start_time": "2022-01-14T13:54:48.738676Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_answer_labels_from_xml(input_xml_file):\n",
    "    results = []\n",
    "    print('parsing...', input_xml_file)\n",
    "\n",
    "    tree = ET.parse(input_xml_file)\n",
    "    root = tree.getroot()\n",
    "    for thread in root:\n",
    "        question_tag = thread[0]\n",
    "        # question_fact_label = question_tag.attrib['RELQ_FACT_LABEL']\n",
    "        # if question_fact_label == 'Factual':\n",
    "        for index, answer_tag in enumerate(thread):\n",
    "            if index ==0 :\n",
    "                question_body = answer_tag[1].text\n",
    "                question_number = answer_tag.attrib['RELQ_ID']\n",
    "                if(question_body==None):\n",
    "                    question_body=\"none\"\n",
    "            if index > 0: # the 0 index was processed above - it is the question\n",
    "                # answer_fact_label = answer_tag.attrib['RELC_FACT_LABEL']\n",
    "                answer_id = answer_tag.attrib['RELC_ID']\n",
    "                answer_body = answer_tag[0].text\n",
    "                answer_number = answer_tag.attrib['RELC_ID']\n",
    "                if(answer_body==None):\n",
    "                    answer_body=\"none\"\n",
    "                # label = get_label(answer_fact_label, ANSWER_LABELS_MAPPING)\n",
    "                label = test_label_array.index(answer_tag.attrib['RELC_RELEVANCE2RELQ'])\n",
    "\n",
    "                # if label > -1:\n",
    "                results.append([question_number,question_body,answer_number,answer_body,label])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c01fecf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T13:54:49.010674Z",
     "start_time": "2022-01-14T13:54:48.879315Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reads answer labels from file in the task input format.\n",
    "def read_question_labels_from_xml(input_xml_file):\n",
    "    labels = []\n",
    "    print('parsing...', input_xml_file)\n",
    "    tree = ET.parse(input_xml_file)\n",
    "    root = tree.getroot()\n",
    "    for thread in root:\n",
    "        question_tag = thread[0]\n",
    "        question_id = question_tag.attrib['RELQ_ID']\n",
    "        question_fact_label = question_tag.attrib['RELQ_FACT_LABEL']\n",
    "        question_body = thread[0][1].text\n",
    "        label = get_label(question_fact_label, QUESTION_LABELS_MAPPING)\n",
    "        item = []\n",
    "        item.append(question_id)\n",
    "        item.append(question_body)\n",
    "        item.append(label)\n",
    "        labels.append(item)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e01158e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T13:54:49.125993Z",
     "start_time": "2022-01-14T13:54:49.031052Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_no_id_labels(labels):\n",
    "    no_id_labels = map(lambda item:list(filter(lambda x:item.index(x)!=0,item)),labels)\n",
    "    return list(no_id_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1d942b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T13:54:50.247084Z",
     "start_time": "2022-01-14T13:54:49.145841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing... train_data.xml\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'Good' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fec91b468e2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_answer_labels_from_xml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_data.xml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-d00e627df534>\u001b[0m in \u001b[0;36mread_answer_labels_from_xml\u001b[1;34m(input_xml_file)\u001b[0m\n\u001b[0;32m     23\u001b[0m                     \u001b[0manswer_body\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"none\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[1;31m# label = get_label(answer_fact_label, ANSWER_LABELS_MAPPING)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_label_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer_tag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RELC_RELEVANCE2RELQ'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;31m# if label > -1:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'Good' is not in list"
     ]
    }
   ],
   "source": [
    "result = read_answer_labels_from_xml(\"train_data.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ae302",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T13:54:50.255555Z",
     "start_time": "2022-01-14T13:54:43.161Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_result = read_answer_labels_from_xml(\"test_data.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f22cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T13:54:50.261537Z",
     "start_time": "2022-01-14T13:54:46.585Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "dicts = []\n",
    "corpus = []\n",
    "labels = []\n",
    "\n",
    "output = [[\"\", \"\", \"\", \"\", \"\"]]\n",
    "\n",
    "for line in dev_result:\n",
    "    tokens = nltk.word_tokenize(line[1])\n",
    "    filtered_sentence = [w for w in tokens if not w.lower() in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    words = [word for word in filtered_sentence if word.isalpha()]\n",
    "    porter = PorterStemmer()\n",
    "    q_stemmed = [porter.stem(word) for word in words]\n",
    "\n",
    "    tokens = nltk.word_tokenize(line[3])\n",
    "    filtered_sentence = [w for w in tokens if not w.lower() in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    words = [word for word in filtered_sentence if word.isalpha()]\n",
    "    porter = PorterStemmer()\n",
    "    a_stemmed = [porter.stem(word) for word in words]\n",
    "    \n",
    "\n",
    "    dict = {\n",
    "        \"question number\": line[0],\n",
    "        \"question\": q_stemmed,\n",
    "        \"answer number\": line[2],\n",
    "        \"answer\": a_stemmed,\n",
    "        \"Label\": line[4],\n",
    "    }\n",
    "    dicts.append(dict)\n",
    "    \n",
    "    q_string_tokens=' '.join([str(elem) for elem in q_stemmed])\n",
    "    a_string_tokens=' '.join([str(elem) for elem in a_stemmed])\n",
    "\n",
    "    temp = [line[0], q_string_tokens, line[2], a_string_tokens, line[4]]\n",
    "    output.append(temp)\n",
    "\n",
    "import json\n",
    "with open('outputfile.csv', 'w') as fout:\n",
    "    json.dump(dicts, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9246c20c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T08:55:53.168765Z",
     "start_time": "2022-01-13T08:55:52.986252Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "pandas_data = pandas.DataFrame(output)\n",
    "pandas_data.to_csv(\"pa_pp_train_data.csv\",sep=\",\",header=True,index=False,encoding=\"utf-8\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae364fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T12:35:41.286597Z",
     "start_time": "2022-01-13T12:35:41.249696Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "pandas_data = pandas.DataFrame(output)\n",
    "pandas_data.to_csv(\"pa_pp_test_data.csv\",sep=\",\",header=True,index=False,encoding=\"utf-8\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aba8486",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T13:55:11.360661Z",
     "start_time": "2022-01-14T13:55:11.354678Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_KB_selector(func, X, y, k):\n",
    "    if func == \"chi2\":\n",
    "        return SelectKBest(chi2, k=k).fit(X, y)\n",
    "    if func == \"f_classif\":\n",
    "        return SelectKBest(f_classif, k=k).fit(X, y)\n",
    "    if func == \"mutual_info_classif\":\n",
    "        return SelectKBest(mutual_info_classif, k=k).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1955079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T13:55:19.416993Z",
     "start_time": "2022-01-14T13:55:19.212020Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "||\n",
    ">>>>>>>\n",
    "'''\n",
    "# pp_train_data\n",
    "pp_train_data_file = open('pa_pp_train_data.csv', 'r', encoding = \"utf8\")\n",
    "pp_train_data_reader = csv.reader(pp_train_data_file)\n",
    "binary_label = []\n",
    "for line in pp_train_data_reader:\n",
    "    if line[4] == '2':\n",
    "        binary_label.append(1)\n",
    "    else:\n",
    "        binary_label.append(0)\n",
    "# print (binary_label)\n",
    " \n",
    "pp_train_data_file_2 = open('pa_pp_train_data.csv', 'r', encoding = \"utf8\")\n",
    "pp_train_data_reader_2 = csv.reader(pp_train_data_file_2)\n",
    "\n",
    "questions_number_array = []\n",
    "questions_array = []\n",
    "answer_number_array = []\n",
    "answer_array = []\n",
    "label_array = []\n",
    "\n",
    "for line in pp_train_data_reader_2:\n",
    "    questions_number_array.append(line[0])\n",
    "    questions_array.append(line[1])\n",
    "    answer_number_array.append(line[2])\n",
    "    answer_array.append(line[3])\n",
    "#     label_array.append(line[4])  \n",
    "label_array = binary_label\n",
    "#print(questions_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffde3952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T13:55:20.452890Z",
     "start_time": "2022-01-14T13:55:20.435488Z"
    }
   },
   "outputs": [],
   "source": [
    "concatqa_train = []\n",
    "# print(len(questions_array))\n",
    "for i in range (0, len(questions_array)):\n",
    "    temp = questions_array[i] + \" \" + answer_array[i]\n",
    "    concatqa_train.append(temp)\n",
    "#print(concatqa_train)\n",
    "# print(len(concatqa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0b040473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T09:16:42.263351Z",
     "start_time": "2022-01-13T09:16:42.128470Z"
    }
   },
   "outputs": [],
   "source": [
    "pandas_data = pandas.DataFrame(questions_array)\n",
    "pandas_data.to_csv(\"questions_array.csv\",sep=\",\",index=False,encoding=\"utf-8\")\n",
    "pandas_data = pandas.DataFrame(answer_array)\n",
    "pandas_data.to_csv(\"answer_array.csv\",sep=\",\",index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0e9f0f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:06:16.174831Z",
     "start_time": "2022-01-14T16:06:15.947598Z"
    }
   },
   "outputs": [],
   "source": [
    "# pp_dev_data\n",
    "pp_dev_data_file = open('pa_pp_test_data.csv', 'r', encoding = \"utf8\")\n",
    "pp_dev_data_reader = csv.reader(pp_dev_data_file)\n",
    "\n",
    "dev_binary_label = []\n",
    "for line in pp_dev_data_reader:\n",
    "    if line[4] == '2':\n",
    "        dev_binary_label.append(1)\n",
    "    else:\n",
    "        dev_binary_label.append(0)\n",
    "# print (dev_binary_label)\n",
    "\n",
    "pp_dev_data_file_2 = open('pa_pp_test_data.csv', 'r', encoding = \"utf8\")\n",
    "pp_dev_data_reader_2 = csv.reader(pp_dev_data_file_2)\n",
    "\n",
    "dev_questions_number_array = []\n",
    "dev_questions_array = []\n",
    "dev_answer_number_array = []\n",
    "dev_answer_array = []\n",
    "dev_label_array = []\n",
    "\n",
    "for line in pp_dev_data_reader_2:\n",
    "    dev_questions_number_array.append(line[0])\n",
    "    dev_questions_array.append(line[1])\n",
    "    dev_answer_number_array.append(line[2])\n",
    "    dev_answer_array.append(line[3])\n",
    "#     dev_label_array.append(line[4])\n",
    "#print(dev_questions_array)\n",
    "dev_label_array = dev_binary_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f39bab1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:06:22.534160Z",
     "start_time": "2022-01-14T16:06:22.523362Z"
    }
   },
   "outputs": [],
   "source": [
    "concatqa_dev = []\n",
    "# print(len(dev_questions_array))\n",
    "for i in range (0, len(dev_questions_array)):\n",
    "    temp = dev_questions_array[i] + \" \" + dev_answer_array[i]\n",
    "    concatqa_dev.append(temp)\n",
    "# print(concatqa_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c5633",
   "metadata": {},
   "source": [
    "# Step 2 & 3: Feature Extraction & MLP\n",
    "<div style=\"direction:rtl  ; font-family: 'Nunito', sans-serif;\" > \n",
    "    پس از انجام مراحل پیش‌پردازش داده‌ها را برای مرحله استخراج ویژگی آماده‌سازی می‌کنیم. چون در صورت تمرین دسته‌بندی باینری خواسته شده که در آن کلاس‌های مورد تقاضا True  به ازای پاسخ‌های Good و False به ازای پاسخ‌های Bad و PotentiallyUseful است، در این گام مقادیر label_array را برای ورودی 2 به 1 و برای ورودی‌های 1 و 0 را به 0 تبدیل می‌کنیم. \n",
    "اغلب روش‌های یادگیری ماشین بر روی داده‌های عددی قابل اجرا هستند و برای استفاده و اجرای آن‌ها روی داده‌های متنی نیاز به تبدیل متون به مجموعه اعداد است. پس هدف رویکردهای مختلف تبدیل متن به بردارهای عددی، استخراج و انتخاب مجموعه‌ای از ویژگی‌های مناسب از متون زبان طبیعی است. لذا انتخاب ویژگی مرحله‌ای بسیار مهم در فعالیت ما به شمار می‌رود، زیرا در این مرحله باید واژه‌های کلیدی انتخاب ‌شوند تا به عنوان بهترین نمایش‌دهنده برای سند متنی مورد استفاده قرار بگیرند. اگر تعداد واژه‌های کلیدی انتخاب شده کم باشد صحت و کارایی سیستم تحت تاثیر قرار می‌گیرد و کاهش می‌یابد و در مقابل اگر تعداد واژه‌های کلیدی انتخاب شده زیاد باشد باعث کاهش کارایی سیستم در بعد زمان خواهد شد و سرعت آموزش در فاز آموزش پایین می‌آید. \n",
    "روش SelectKBest، K ویژگی با بهترین معیار آماری را نگه داشته و از باقی ویژگی‌ها صرف نظر می‌کند که در اینجا مقدار K می‌تواند به وسیله ما مشخص شود. \n",
    "    \n",
    "در این پروژه پس از استخراج 50000 ویژگی با روش‌های ذکر شده بالا، برای انتخاب ویژگی از روش‌ SelectKBest با توابع آماری chi2، f_classif، f_regression و mutual_info_regression برای انتخاب ویژگی‌های مجموعه‌های آموزش، توسعه و تست استفاده کرده و مدل شبکه پرسپترون چند لایه را با ویژگی‌های بدست آمده از این روش‌ها از مجموعه آموزش، آموزش داده و مدل آموزش داده شده را بر روی مجموعه dev_data با پارامترهای مختلف اجرا کرده و سعی کردیم تا بهترین پیکربندی برای هر مدل که معیار score را بیشینه می‌کند را با تحلیل و تغییر دادن پیکربندی‌ها بدست آوریم. در جدول زیر معیار score برای منتخب برخی از روش‌های گوناگون که تست شده قابل ملاحظه است.\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8773dfd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:07:57.687266Z",
     "start_time": "2022-01-14T16:07:57.683840Z"
    }
   },
   "outputs": [],
   "source": [
    "max_f = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c4bb43ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:07:59.835968Z",
     "start_time": "2022-01-14T16:07:58.186922Z"
    }
   },
   "outputs": [],
   "source": [
    "#vectorize by count\n",
    "#, ngram_range = (1, 3)\n",
    "count_vectorizer = CountVectorizer(max_features = max_f)\n",
    "X_count_train = count_vectorizer.fit_transform(concatqa_train).toarray()\n",
    "y_count_train = label_array\n",
    "D_count_train = numpy.array(X_count_train)\n",
    "F_train = numpy.array(y_count_train)\n",
    "# terms = count_vectorizer.get_feature_names_out()\n",
    "# print(\"len doc\", count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dede0387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:08:00.472935Z",
     "start_time": "2022-01-14T16:08:00.114740Z"
    }
   },
   "outputs": [],
   "source": [
    "#vectorize by count\n",
    "count_vectorizer = CountVectorizer(max_features = max_f)\n",
    "X_count_dev = count_vectorizer.fit_transform(concatqa_dev).toarray()\n",
    "y_count_dev = dev_label_array\n",
    "D_count_dev = numpy.array(X_count_dev)\n",
    "F_dev = numpy.array(y_count_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "38855580",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:08:02.368786Z",
     "start_time": "2022-01-14T16:08:00.726178Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features = max_f)\n",
    "X_tfidf_train = tfidf_vectorizer.fit_transform(concatqa_train).toarray()\n",
    "y_tfidf_train = label_array\n",
    "D_tfidf_train = numpy.array(X_tfidf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "34e54f4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:08:03.059892Z",
     "start_time": "2022-01-14T16:08:02.685479Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features = max_f)\n",
    "X_tfidf_dev = tfidf_vectorizer.fit_transform(concatqa_dev).toarray()\n",
    "#S_X_tfidf_dev = SelectKBest(chi2, k = 20)\n",
    "y_tfidf_dev = dev_label_array\n",
    "D_tfidf_dev = numpy.array(X_tfidf_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddea465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25_as_relevence_score(dev_questions_array, dev_answer_array):\n",
    "    # calculate BM25 as \"fake\" relevence score, return as list\n",
    "    tokenized_corpus = [doc.split(\" \") for doc in sentences]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    query = caption\n",
    "    tokenized_query = query.split(\" \")\n",
    "    cap_doc_scores = bm25.get_scores(tokenized_query)\n",
    "    # print(cap_doc_scores)\n",
    "    rel = np.zeros(len(cap_doc_scores))\n",
    "return rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "157542c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:08:03.316087Z",
     "start_time": "2022-01-14T16:08:03.310104Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, f_regression, mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6b83fdca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:08:04.734443Z",
     "start_time": "2022-01-14T16:08:03.564045Z"
    }
   },
   "outputs": [],
   "source": [
    "input_D_train = np.append(D_count_train, D_tfidf_train , axis=1)\n",
    "input_D_dev = np.append(D_count_dev, D_tfidf_dev , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8eeabdbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:08:48.748166Z",
     "start_time": "2022-01-14T16:08:48.739189Z"
    }
   },
   "outputs": [],
   "source": [
    "def SelectKBest_options(input_feature_selection, k_feature, max_i):\n",
    "    aaa = SelectKBest(input_feature_selection, k = k_feature).fit_transform(input_D_train, F_train)\n",
    "    bbb = SelectKBest(input_feature_selection, k = k_feature).fit_transform(input_D_dev, F_dev)\n",
    "    clf = MLPClassifier(random_state=1, max_iter=max_i).fit(aaa, F_train)\n",
    "    clf.predict_proba(bbb[:1])\n",
    "    clf.predict(bbb[:, :])\n",
    "    clf.score(bbb, F_dev)\n",
    "    print(\"Score with\",input_feature_selection, \"k=\",k_feature, \"max_iter=\",max_i,\"is:\",clf.score(bbb, F_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "305dfd59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:10:57.523612Z",
     "start_time": "2022-01-14T16:08:49.965310Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 50 max_iter= 20 is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 100 max_iter= 20 is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 200 max_iter= 20 is: 0.9996587030716724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 300 max_iter= 20 is: 0.9996587030716724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 400 max_iter= 20 is: 0.989419795221843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 500 max_iter= 20 is: 0.9935153583617747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 600 max_iter= 20 is: 0.9843003412969283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 50 max_iter= 50 is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 100 max_iter= 50 is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 200 max_iter= 50 is: 0.9921501706484641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 300 max_iter= 50 is: 0.9621160409556314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 400 max_iter= 50 is: 0.9156996587030717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function chi2 at 0x00000281FD138790> k= 500 max_iter= 50 is: 0.956655290102389\n",
      "Score with <function chi2 at 0x00000281FD138790> k= 600 max_iter= 50 is: 0.8303754266211604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SelectKBest_options(chi2, 50, 20)\n",
    "SelectKBest_options(chi2, 100, 20)\n",
    "SelectKBest_options(chi2, 200, 20)\n",
    "SelectKBest_options(chi2, 300, 20)\n",
    "SelectKBest_options(chi2, 400, 20)\n",
    "SelectKBest_options(chi2, 500, 20)\n",
    "SelectKBest_options(chi2, 600, 20)\n",
    "SelectKBest_options(chi2, 50, 50)\n",
    "SelectKBest_options(chi2, 100, 50)\n",
    "SelectKBest_options(chi2, 200, 50)\n",
    "SelectKBest_options(chi2, 300, 50)\n",
    "SelectKBest_options(chi2, 400, 50)\n",
    "SelectKBest_options(chi2, 500, 50)\n",
    "SelectKBest_options(chi2, 600, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8274292b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:00:08.483037Z",
     "start_time": "2022-01-14T14:56:54.128715Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 50 max_iter= 20 is: 0.6930327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 100 max_iter= 20 is: 0.6864754098360656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 200 max_iter= 20 is: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 300 max_iter= 20 is: 0.639344262295082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 400 max_iter= 20 is: 0.5762295081967214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 500 max_iter= 20 is: 0.5045081967213115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 600 max_iter= 20 is: 0.5565573770491803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 50 max_iter= 50 is: 0.6823770491803278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 100 max_iter= 50 is: 0.6823770491803278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 200 max_iter= 50 is: 0.5733606557377049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 300 max_iter= 50 is: 0.6184426229508196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 400 max_iter= 50 is: 0.5672131147540984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_classif at 0x00000281FD138670> k= 500 max_iter= 50 is: 0.5045081967213115\n",
      "Score with <function f_classif at 0x00000281FD138670> k= 600 max_iter= 50 is: 0.5557377049180328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SelectKBest_options(f_classif, 50, 20)\n",
    "SelectKBest_options(f_classif, 100, 20)\n",
    "SelectKBest_options(f_classif, 200, 20)\n",
    "SelectKBest_options(f_classif, 300, 20)\n",
    "SelectKBest_options(f_classif, 400, 20)\n",
    "SelectKBest_options(f_classif, 500, 20)\n",
    "SelectKBest_options(f_classif, 600, 20)\n",
    "SelectKBest_options(f_classif, 50, 50)\n",
    "SelectKBest_options(f_classif, 100, 50)\n",
    "SelectKBest_options(f_classif, 200, 50)\n",
    "SelectKBest_options(f_classif, 300, 50)\n",
    "SelectKBest_options(f_classif, 400, 50)\n",
    "SelectKBest_options(f_classif, 500, 50)\n",
    "SelectKBest_options(f_classif, 600, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f3d8f05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T15:02:04.342502Z",
     "start_time": "2022-01-14T15:00:08.674205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 50 max_iter= 20 is: 0.6930327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 100 max_iter= 20 is: 0.6864754098360656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 200 max_iter= 20 is: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 300 max_iter= 20 is: 0.639344262295082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 400 max_iter= 20 is: 0.5762295081967214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 500 max_iter= 20 is: 0.5045081967213115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 600 max_iter= 20 is: 0.5565573770491803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 50 max_iter= 50 is: 0.6823770491803278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 100 max_iter= 50 is: 0.6823770491803278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 200 max_iter= 50 is: 0.5733606557377049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 300 max_iter= 50 is: 0.6184426229508196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 400 max_iter= 50 is: 0.5672131147540984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with <function f_regression at 0x00000281FD138940> k= 500 max_iter= 50 is: 0.5045081967213115\n",
      "Score with <function f_regression at 0x00000281FD138940> k= 600 max_iter= 50 is: 0.5557377049180328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SelectKBest_options(f_regression, 50, 20)\n",
    "SelectKBest_options(f_regression, 100, 20)\n",
    "SelectKBest_options(f_regression, 200, 20)\n",
    "SelectKBest_options(f_regression, 300, 20)\n",
    "SelectKBest_options(f_regression, 400, 20)\n",
    "SelectKBest_options(f_regression, 500, 20)\n",
    "SelectKBest_options(f_regression, 600, 20)\n",
    "SelectKBest_options(f_regression, 50, 50)\n",
    "SelectKBest_options(f_regression, 100, 50)\n",
    "SelectKBest_options(f_regression, 200, 50)\n",
    "SelectKBest_options(f_regression, 300, 50)\n",
    "SelectKBest_options(f_regression, 400, 50)\n",
    "SelectKBest_options(f_regression, 500, 50)\n",
    "SelectKBest_options(f_regression, 600, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d0d1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T14:36:35.880905Z",
     "start_time": "2022-01-14T14:35:21.996830Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "02030f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:12:35.906554Z",
     "start_time": "2022-01-14T16:10:57.737622Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7491467576791809"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_D_train = np.append(D_count_train, D_tfidf_train , axis=1)\n",
    "input_D_dev = np.append(D_count_dev, D_tfidf_dev , axis=1)\n",
    "clf = MLPClassifier(random_state=1, max_iter=50).fit(input_D_train, F_train)\n",
    "clf.predict_proba(input_D_dev[:1])\n",
    "clf.predict(input_D_dev[:, :])\n",
    "clf.score(input_D_dev, F_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "52dbad31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T16:14:00.167447Z",
     "start_time": "2022-01-14T16:13:59.202012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question Number</th>\n",
       "      <th>Answer Number</th>\n",
       "      <th>Predict Rank</th>\n",
       "      <th>Predict Proba</th>\n",
       "      <th>Answer class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.994583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.998625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.974426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2930 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Question Number Answer Number  Predict Rank  Predict Proba  Answer class\n",
       "0           Q388_R14   Q388_R14_C9             1       0.999339             0\n",
       "1           Q388_R14   Q388_R14_C5             2       0.997436             0\n",
       "2           Q388_R14   Q388_R14_C7             3       0.996494             0\n",
       "3           Q388_R14   Q388_R14_C1             4       0.994583             0\n",
       "4           Q388_R14   Q388_R14_C6             5       0.988482             0\n",
       "...              ...           ...           ...            ...           ...\n",
       "2925         Q475_R9    Q475_R9_C2             6       0.999692             0\n",
       "2926         Q475_R9    Q475_R9_C3             7       0.998782             0\n",
       "2927         Q475_R9    Q475_R9_C4             8       0.998625             0\n",
       "2928         Q475_R9    Q475_R9_C7             9       0.996250             0\n",
       "2929         Q475_R9    Q475_R9_C1            10       0.974426             0\n",
       "\n",
       "[2930 rows x 5 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = []\n",
    "for i in range (0, int((len(dev_questions_array)/10))):\n",
    "    numbers = numbers + [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# print(numbers)\n",
    "# print(len(numbers))\n",
    "max_clf_predict_proba = np.amax(clf_predict_proba, 1)\n",
    "col_1 = dev_questions_number_array\n",
    "col_2 = dev_answer_number_array\n",
    "col_3 = numbers \n",
    "col_4 = max_clf_predict_proba\n",
    "col_5 = clf_predict_class\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "df1.insert(0, \"Question Number\", col_1, True)\n",
    "df1.insert(1, \"Answer Number\", col_2, True)\n",
    "df1.insert(2, \"Predict Proba\", col_4, True)\n",
    "df1.insert(3, \"Answer class\", col_5, True)\n",
    "\n",
    "df2 = df1.groupby([\"Question Number\"]).apply(lambda x: x.sort_values([\"Predict Proba\"], ascending = False)).reset_index(drop=True)\n",
    "df2.insert(2, \"Predict Rank\", col_3, True)\n",
    "\n",
    "df2.to_csv(\"IR-Final-Prj-Step_3.csv\",sep=\" \",header=True,index=False,encoding=\"utf-8\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3cf67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T14:26:38.709933Z",
     "start_time": "2022-01-14T14:26:30.004997Z"
    },
    "cell_style": "center"
   },
   "source": [
    "# Step 4: Glove\n",
    "<div style=\"direction:rtl  ; font-family: 'Nunito', sans-serif;\" > \n",
    "    \n",
    "ایده اصلی پشت جاسازی کلمه GloVe این است که رابطه بین کلمات را به کمک آمار بدست آوریم. برخلاف ماتریس رخداد، ماتریس co-occurrence می‌گوید که چند بار یک جفت کلمه خاص با هم اتفاق می‌افتد. هر مقدار در ماتریس co-occurrence نشان دهنده یک جفت کلمه است که با هم اتفاق می‌افتند.\n",
    "برای پیاده¬سازی این قسمت از کتابخانه zeugma.embeddings استفاده کردیم. ابتدا یک transformer را با استفاده از تابع EmbeddingTransformer که پارامتر 'glove' به آن داده شده است می¬سازیم و سپس داده¬ی ورودی را به آن می¬دهیم که با این بازنمایی ویژگی¬های آن استخراج شود. در ادامه نیز خروجی این نمایش را به همراه داده¬ی های برچسب آموزشی به شبکه MLP می¬دهیم. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35500172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T14:26:29.760590Z",
     "start_time": "2022-01-14T14:26:22.167269Z"
    }
   },
   "outputs": [],
   "source": [
    "from zeugma.embeddings import EmbeddingTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff57649",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = EmbeddingTransformer('glove')\n",
    "X_glove_train = glove.transform(concatqa_train)\n",
    "y_train = label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7475b580",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T14:26:15.537552Z",
     "start_time": "2022-01-14T14:26:10.026809Z"
    }
   },
   "outputs": [],
   "source": [
    "D_glove_train = numpy.array(X_glove_train)\n",
    "F_train = numpy.array(y_train)\n",
    "glove_dev = EmbeddingTransformer('glove')\n",
    "X_glove_dev = glove_dev.transform(concatqa_dev)\n",
    "y_glove_dev = dev_label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4d15b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:54:40.530298Z",
     "start_time": "2022-01-12T14:54:40.525311Z"
    }
   },
   "outputs": [],
   "source": [
    "D_glove_dev = numpy.array(X_glove_dev)\n",
    "F_dev = numpy.array(y_glove_dev)\n",
    "input_D_train = D_glove_train\n",
    "input_D_dev = D_glove_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf6d9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T14:26:21.933859Z",
     "start_time": "2022-01-14T14:26:15.759417Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=100).fit(input_D_train, F_train)\n",
    "clf.predict_proba(input_D_dev[:1])\n",
    "clf.predict(input_D_dev[:5, :])\n",
    "clf.score(input_D_dev, F_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "825c39d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T17:30:43.324766Z",
     "start_time": "2022-01-14T17:30:42.456652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question Number</th>\n",
       "      <th>Answer Number</th>\n",
       "      <th>Predict Rank</th>\n",
       "      <th>Predict Proba</th>\n",
       "      <th>Answer class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.994583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.998625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.974426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2930 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Question Number Answer Number  Predict Rank  Predict Proba  Answer class\n",
       "0           Q388_R14   Q388_R14_C9             1       0.999339             0\n",
       "1           Q388_R14   Q388_R14_C5             2       0.997436             0\n",
       "2           Q388_R14   Q388_R14_C7             3       0.996494             0\n",
       "3           Q388_R14   Q388_R14_C1             4       0.994583             0\n",
       "4           Q388_R14   Q388_R14_C6             5       0.988482             0\n",
       "...              ...           ...           ...            ...           ...\n",
       "2925         Q475_R9    Q475_R9_C2             6       0.999692             0\n",
       "2926         Q475_R9    Q475_R9_C3             7       0.998782             0\n",
       "2927         Q475_R9    Q475_R9_C4             8       0.998625             0\n",
       "2928         Q475_R9    Q475_R9_C7             9       0.996250             0\n",
       "2929         Q475_R9    Q475_R9_C1            10       0.974426             0\n",
       "\n",
       "[2930 rows x 5 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_predict_proba = clf.predict_proba(input_D_dev[:])\n",
    "clf_predict_class = clf.predict(input_D_dev[:, :])\n",
    "numbers = []\n",
    "for i in range (0, int((len(dev_questions_array)/10))):\n",
    "    numbers = numbers + [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# print(numbers)\n",
    "# print(len(numbers))\n",
    "max_clf_predict_proba = np.amax(clf_predict_proba, 1)\n",
    "col_1 = dev_questions_number_array\n",
    "col_2 = dev_answer_number_array\n",
    "col_3 = numbers \n",
    "col_4 = max_clf_predict_proba\n",
    "col_5 = clf_predict_class\n",
    "\n",
    "df3 = pd.DataFrame()\n",
    "df3.insert(0, \"Question Number\", col_1, True)\n",
    "df3.insert(1, \"Answer Number\", col_2, True)\n",
    "df3.insert(2, \"Predict Proba\", col_4, True)\n",
    "df3.insert(3, \"Answer class\", col_5, True)\n",
    "\n",
    "df4 = df3.groupby([\"Question Number\"]).apply(lambda x: x.sort_values([\"Predict Proba\"], ascending = False)).reset_index(drop=True)\n",
    "df4.insert(2, \"Predict Rank\", col_3, True)\n",
    "\n",
    "df4.to_csv(\"IR-Final-Prj-Step_44.csv\",sep=\" \",header=True,index=False,encoding=\"utf-8\")\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dadadf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T12:32:05.808310Z",
     "start_time": "2022-01-12T12:31:30.201Z"
    }
   },
   "source": [
    "# Step 5: BERT Finetuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f23848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_sklearn import BertClassifier\n",
    "from bert_sklearn import BertRegressor\n",
    "from bert_sklearn import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817bc220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "# text/text pair classification\n",
    "model = BertClassifier()   \n",
    "# text/text pair regression\n",
    "# model = BertRegressor()       \n",
    "# token sequence classification\n",
    "# model = BertTokenClassifier() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetune model\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "# make probabilty predictions\n",
    "y_pred = model.predict_proba(X_test)\n",
    "# score model on test data\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "48524a48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T17:38:14.041341Z",
     "start_time": "2022-01-14T17:38:13.751985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question Number</th>\n",
       "      <th>Answer Number</th>\n",
       "      <th>Predict Rank</th>\n",
       "      <th>Predict Proba</th>\n",
       "      <th>Answer class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.994583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q388_R14</td>\n",
       "      <td>Q388_R14_C6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.998625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>Q475_R9</td>\n",
       "      <td>Q475_R9_C1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.974426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2930 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Question Number Answer Number  Predict Rank  Predict Proba  Answer class\n",
       "0           Q388_R14   Q388_R14_C9             1       0.999339             0\n",
       "1           Q388_R14   Q388_R14_C5             2       0.997436             0\n",
       "2           Q388_R14   Q388_R14_C7             3       0.996494             0\n",
       "3           Q388_R14   Q388_R14_C1             4       0.994583             0\n",
       "4           Q388_R14   Q388_R14_C6             5       0.988482             0\n",
       "...              ...           ...           ...            ...           ...\n",
       "2925         Q475_R9    Q475_R9_C2             6       0.999692             0\n",
       "2926         Q475_R9    Q475_R9_C3             7       0.998782             0\n",
       "2927         Q475_R9    Q475_R9_C4             8       0.998625             0\n",
       "2928         Q475_R9    Q475_R9_C7             9       0.996250             0\n",
       "2929         Q475_R9    Q475_R9_C1            10       0.974426             0\n",
       "\n",
       "[2930 rows x 5 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "df6 = df3.groupby([\"Question Number\"]).apply(lambda x: x.sort_values([\"Predict Proba\"], ascending = False)).reset_index(drop=True)\n",
    "df6.insert(2, \"Predict Rank\", col_3, True)\n",
    "df6.to_csv(\"IR-Final-Prj-Step_44.csv\",sep=\" \",header=True,index=False,encoding=\"utf-8\")\n",
    "df6\n",
    "df6.to_csv(\"IR-Final-Prj-Step_55.csv\",sep=\" \",header=True,index=False,encoding=\"utf-8\")\n",
    "model.save(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fad094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T15:12:46.915908Z",
     "start_time": "2022-01-11T15:12:46.656096Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9d60f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T14:52:25.136470Z",
     "start_time": "2022-01-12T14:52:25.132480Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe3ae0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T08:21:19.680202Z",
     "start_time": "2022-01-13T08:21:19.675219Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950c3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c847cea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T14:50:26.253165Z",
     "start_time": "2022-01-14T14:50:26.248180Z"
    }
   },
   "outputs": [],
   "source": [
    "# ********************************************************************\n",
    "# # datafile = open('train_data.csv', 'r', encoding=\"utf8\")\n",
    "# myreader = csv.reader(datafile)\n",
    "# X = []\n",
    "# y = []\n",
    "# temp = [\"0\", \"0\"]\n",
    "# for qqaa in myreader:\n",
    "#     tx = [\" \", \" \"]\n",
    "#     ty = 5\n",
    "#     temp[0] = qqaa[1]\n",
    "# #     print(temp[0])\n",
    "#     temp[1] = qqaa[3]\n",
    "# #     print(temp[1])\n",
    "#     tx = [temp[0], temp[1]]\n",
    "#     ty = qqaa[4]\n",
    "#     X.append(tx)\n",
    "#     y.append(ty)\n",
    "# print(X[20], X[21])\n",
    "# print(X[2])\n",
    "# print(y[2])\n",
    "# selector = SelectFromModel(estimator=LogisticRegression()).fit(XX, yy)\n",
    "# selector.estimator_.coef_\n",
    "# print(get_KB_selector(\"f_classif\", d, f, k))\n",
    "# //\n",
    "# selector = get_KB_selector(\"f_classif\", d, f, k)\n",
    "# d = selector.transform(d)\n",
    "# XX = numpy.array(d)\n",
    "# yy = numpy.array(f)\n",
    "# clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "# clf.fit(XX, yy)\n",
    "# td, tf = reader.readVTestData('./dm_final/data/V1_ECFP4.csv')\n",
    "# td = selector.transform(td)\n",
    "# r = clf.predict(td)\n",
    "# y_true = tf\n",
    "# y_pred = r.tolist()\n",
    "# utils.show_result(y_true, y_pred)\n",
    "# with open('X.txt', 'w') as f:\n",
    "#     f.write(str(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "911a8d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T14:50:25.613426Z",
     "start_time": "2022-01-14T14:50:25.609436Z"
    }
   },
   "outputs": [],
   "source": [
    "# fe_temp = [\"0\", \"0\"]\n",
    "# for qqaa in myreader:\n",
    "#     tx = [\" \", \" \"]\n",
    "#     ty = 5\n",
    "#     fe_temp[0] = qqaa[1]\n",
    "# #     print(temp[0])\n",
    "#     fe_temp[1] = qqaa[3]\n",
    "# #     print(temp[1])\n",
    "#     tx = [fe_temp[0], fe_temp[1]]\n",
    "#     ty = qqaa[4]\n",
    "#     X.append(tx)\n",
    "#     y.append(ty)\n",
    "# print(X[20], X[21])\n",
    "# print(X[2])\n",
    "# print(y[2])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
